{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371b205b",
   "metadata": {},
   "source": [
    "# ETL Processes\n",
    "***\n",
    "## Lists of tasks:\n",
    "- ### <del>Consolidating Datasets</del>\n",
    "- ### Normalising/Restructuring Tables\n",
    "- ### Exploratory Data Analysis\n",
    "- ### Data Cleaning\n",
    "- ### Package ETL.py into a Class\n",
    "***\n",
    "\n",
    "## Content:\n",
    "- ### [Consumer Dataset](#Consumer-dataset)\n",
    "- ### [Transaction Dataset](#Transaction-dataset)\n",
    "- ### [Merchant Dataset](#Merchant-dataset)\n",
    "- ### [Data Aggregations](#Aggregation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f83e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 3.1.2\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.7.4 (default, Aug 13 2019 15:17:50)\n",
      "Spark context Web UI available at http://169.254.224.157:4040\n",
      "Spark context available as 'sc' (master = local[*], app id = local-1662463139952).\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Set working directory\n",
    "if not \"/data/tables\" in os.getcwd():\n",
    "    os.chdir(\"../data/tables\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.shell import spark\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 2\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.sql.broadcastTimeout\", -1)\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5458a7a",
   "metadata": {},
   "source": [
    "# Consumer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42f5285b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>address</th><th>state</th><th>postcode</th><th>gender</th><th>consumer_id</th></tr>\n",
       "<tr><td>Yolanda Williams</td><td>413 Haney Gardens...</td><td>WA</td><td>6935</td><td>Female</td><td>1195503</td></tr>\n",
       "<tr><td>Mary Smith</td><td>3764 Amber Oval</td><td>NSW</td><td>2782</td><td>Female</td><td>179208</td></tr>\n",
       "<tr><td>Jill Jones MD</td><td>40693 Henry Greens</td><td>NT</td><td>862</td><td>Female</td><td>1194530</td></tr>\n",
       "<tr><td>Lindsay Jimenez</td><td>00653 Davenport C...</td><td>NSW</td><td>2780</td><td>Female</td><td>154128</td></tr>\n",
       "<tr><td>Rebecca Blanchard</td><td>9271 Michael Mano...</td><td>WA</td><td>6355</td><td>Female</td><td>712975</td></tr>\n",
       "<tr><td>Karen Chapman</td><td>2706 Stewart Oval...</td><td>NSW</td><td>2033</td><td>Female</td><td>407340</td></tr>\n",
       "<tr><td>Andrea Jones</td><td>122 Brandon Cliff</td><td>QLD</td><td>4606</td><td>Female</td><td>511685</td></tr>\n",
       "<tr><td>Stephen Williams</td><td>6804 Wright Crest...</td><td>WA</td><td>6056</td><td>Male</td><td>448088</td></tr>\n",
       "<tr><td>Stephanie Reyes</td><td>5813 Denise Land ...</td><td>NSW</td><td>2482</td><td>Female</td><td>650435</td></tr>\n",
       "<tr><td>Jillian Gonzales</td><td>461 Ryan Common S...</td><td>VIC</td><td>3220</td><td>Female</td><td>1058499</td></tr>\n",
       "<tr><td>Eugene Lucas</td><td>33983 Kevin Drive...</td><td>VIC</td><td>3063</td><td>Undisclosed</td><td>428325</td></tr>\n",
       "<tr><td>Melissa Jones</td><td>13706 Kimberly Port</td><td>WA</td><td>6743</td><td>Female</td><td>1494640</td></tr>\n",
       "<tr><td>Angela Brown PhD</td><td>0236 Mills Land S...</td><td>QLD</td><td>4673</td><td>Female</td><td>1146717</td></tr>\n",
       "<tr><td>Lance Butler</td><td>8943 Kenneth Camp</td><td>VIC</td><td>3332</td><td>Male</td><td>1343547</td></tr>\n",
       "<tr><td>Paul Abbott</td><td>60495 Ryan Hill</td><td>QLD</td><td>4512</td><td>Male</td><td>1463076</td></tr>\n",
       "<tr><td>Tracy Hart</td><td>9671 Jacob Harbor...</td><td>NSW</td><td>2452</td><td>Male</td><td>1356405</td></tr>\n",
       "<tr><td>Alyssa Wilson</td><td>44353 Nathan Ridge</td><td>VIC</td><td>3719</td><td>Female</td><td>1331093</td></tr>\n",
       "<tr><td>Michael Burnett</td><td>89400 Torres Fort</td><td>NSW</td><td>1109</td><td>Male</td><td>80965</td></tr>\n",
       "<tr><td>Victoria Gonzalez</td><td>68657 Johnson Gle...</td><td>TAS</td><td>7276</td><td>Female</td><td>1226530</td></tr>\n",
       "<tr><td>James Norris</td><td>790 Ramos Landing</td><td>VIC</td><td>3234</td><td>Undisclosed</td><td>1390367</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-----------------+--------------------+-----+--------+-----------+-----------+\n",
       "|             name|             address|state|postcode|     gender|consumer_id|\n",
       "+-----------------+--------------------+-----+--------+-----------+-----------+\n",
       "| Yolanda Williams|413 Haney Gardens...|   WA|    6935|     Female|    1195503|\n",
       "|       Mary Smith|     3764 Amber Oval|  NSW|    2782|     Female|     179208|\n",
       "|    Jill Jones MD|  40693 Henry Greens|   NT|     862|     Female|    1194530|\n",
       "|  Lindsay Jimenez|00653 Davenport C...|  NSW|    2780|     Female|     154128|\n",
       "|Rebecca Blanchard|9271 Michael Mano...|   WA|    6355|     Female|     712975|\n",
       "|    Karen Chapman|2706 Stewart Oval...|  NSW|    2033|     Female|     407340|\n",
       "|     Andrea Jones|   122 Brandon Cliff|  QLD|    4606|     Female|     511685|\n",
       "| Stephen Williams|6804 Wright Crest...|   WA|    6056|       Male|     448088|\n",
       "|  Stephanie Reyes|5813 Denise Land ...|  NSW|    2482|     Female|     650435|\n",
       "| Jillian Gonzales|461 Ryan Common S...|  VIC|    3220|     Female|    1058499|\n",
       "|     Eugene Lucas|33983 Kevin Drive...|  VIC|    3063|Undisclosed|     428325|\n",
       "|    Melissa Jones| 13706 Kimberly Port|   WA|    6743|     Female|    1494640|\n",
       "| Angela Brown PhD|0236 Mills Land S...|  QLD|    4673|     Female|    1146717|\n",
       "|     Lance Butler|   8943 Kenneth Camp|  VIC|    3332|       Male|    1343547|\n",
       "|      Paul Abbott|     60495 Ryan Hill|  QLD|    4512|       Male|    1463076|\n",
       "|       Tracy Hart|9671 Jacob Harbor...|  NSW|    2452|       Male|    1356405|\n",
       "|    Alyssa Wilson|  44353 Nathan Ridge|  VIC|    3719|     Female|    1331093|\n",
       "|  Michael Burnett|   89400 Torres Fort|  NSW|    1109|       Male|      80965|\n",
       "|Victoria Gonzalez|68657 Johnson Gle...|  TAS|    7276|     Female|    1226530|\n",
       "|     James Norris|   790 Ramos Landing|  VIC|    3234|Undisclosed|    1390367|\n",
       "+-----------------+--------------------+-----+--------+-----------+-----------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read csv file\n",
    "consumer = spark.read.option(\"delimiter\", \"|\").csv('tbl_consumer.csv', header = True)\n",
    "consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e05d5d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_id = consumer.toPandas()['consumer_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a4ef7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499999"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(consumer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa95663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset details: \n",
      "\tNumber of rows: 499999 \n",
      "\tNumber of distinct Consumer ID: 499999 \n",
      "\tNumber of distinct Postcodes: 3167\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset details: \\n\\tNumber of rows: {consumer.count()}\", \\\n",
    "      f\"\\n\\tNumber of distinct Consumer ID: {consumer.select('consumer_id').distinct().count()}\", \\\n",
    "      f\"\\n\\tNumber of distinct Postcodes: {consumer.select('postcode').distinct().count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708e3afe",
   "metadata": {},
   "source": [
    "Note: \n",
    "- The **address field is fake** and derived from USA street names. We have included it to mimic a more realistic dataset, but the streets themselves are non-existent and if there are any matches, it will be a pure coincidence. <font color='red'>**Not sure what sort of information we can extract here if they are all fake</font> \n",
    "- The **postcode field is accurate** and should be **used for aggregated analysis** for joining with other geospatial datasets for demographic information (i.e ABS datasets) <font color='red'>**Highly relevant for geospatial analysis</font> \n",
    "- There is roughly a **uniform distribution at the state level** (i.e number of consumers per state is the same for all states)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eefd265",
   "metadata": {},
   "source": [
    "### Checking for missing values in consumer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce2c735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_check(sdf):\n",
    "    \"\"\"Check missing values in each column of the spark dataframe\"\"\"\n",
    "    \n",
    "    col_summary = []\n",
    "    for c, dtype in sdf.dtypes:\n",
    "        if dtype == 'string':\n",
    "            col_summary.append(\n",
    "                count(\n",
    "                    when(\n",
    "                        col(c).contains('None') | \\\n",
    "                        col(c).contains('NULL') | \\\n",
    "                        (col(c) == '' ) | \\\n",
    "                        col(c).isNull() | \\\n",
    "                        isnan(c), c\n",
    "                    )\n",
    "                ).alias(c)\n",
    "            )\n",
    "        \n",
    "        elif dtype == 'date':\n",
    "            col_summary.append(\n",
    "                count(\n",
    "                    when(\n",
    "                        col(c).isNull(), c\n",
    "                    )\n",
    "                ).alias(c)\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            sdf = sdf.fillna({c:-99})\n",
    "            col_summary.append(\n",
    "                count(\n",
    "                    when(\n",
    "                        col(c) == -99, c\n",
    "                        \n",
    "                    )\n",
    "                ).alias(c)\n",
    "            )\n",
    "            \n",
    "    return sdf.select(col_summary)\n",
    "                               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e010266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>address</th><th>state</th><th>postcode</th><th>gender</th><th>consumer_id</th></tr>\n",
       "<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-------+-----+--------+------+-----------+\n",
       "|name|address|state|postcode|gender|consumer_id|\n",
       "+----+-------+-----+--------+------+-----------+\n",
       "|   0|      0|    0|       0|     0|          0|\n",
       "+----+-------+-----+--------+------+-----------+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_check(consumer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dbbe73",
   "metadata": {},
   "source": [
    "### Check if there exists invalid postcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bd0af0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>address</th><th>state</th><th>postcode</th><th>gender</th><th>consumer_id</th></tr>\n",
       "<tr><td>Mrs. Cynthia Cook</td><td>483 Caitlyn Valley</td><td>VIC</td><td>8070</td><td>Female</td><td>216120</td></tr>\n",
       "<tr><td>Jennifer Wood</td><td>166 Miller Pass S...</td><td>VIC</td><td>8070</td><td>Female</td><td>1421589</td></tr>\n",
       "<tr><td>Christopher Johnson</td><td>586 Kimberly Pine</td><td>QLD</td><td>9005</td><td>Undisclosed</td><td>747767</td></tr>\n",
       "<tr><td>Natalie Stewart</td><td>06565 Bullock For...</td><td>VIC</td><td>8009</td><td>Female</td><td>1019378</td></tr>\n",
       "<tr><td>Heather Walker</td><td>57761 Erin Square</td><td>VIC</td><td>8011</td><td>Female</td><td>175536</td></tr>\n",
       "<tr><td>Nicole Aguirre</td><td>25436 Shepherd St...</td><td>VIC</td><td>8001</td><td>Female</td><td>506458</td></tr>\n",
       "<tr><td>Kathleen Garcia</td><td>369 Cannon Parkways</td><td>VIC</td><td>8120</td><td>Female</td><td>805144</td></tr>\n",
       "<tr><td>Wendy Shepard</td><td>4120 Christopher ...</td><td>VIC</td><td>8111</td><td>Female</td><td>1242001</td></tr>\n",
       "<tr><td>Joyce Wilson DDS</td><td>10840 David Trail</td><td>VIC</td><td>8002</td><td>Female</td><td>940835</td></tr>\n",
       "<tr><td>Alyssa Harris</td><td>617 Carrie Track</td><td>VIC</td><td>8010</td><td>Undisclosed</td><td>89478</td></tr>\n",
       "<tr><td>Curtis Jimenez</td><td>563 Brown Creek S...</td><td>VIC</td><td>8070</td><td>Male</td><td>807165</td></tr>\n",
       "<tr><td>Aaron Tanner</td><td>9235 Mcneil Overp...</td><td>VIC</td><td>8008</td><td>Undisclosed</td><td>556898</td></tr>\n",
       "<tr><td>Arthur Williams</td><td>99382 Carlos Squares</td><td>QLD</td><td>9013</td><td>Male</td><td>468665</td></tr>\n",
       "<tr><td>Robert Miller</td><td>66326 Tina Tunnel</td><td>VIC</td><td>8120</td><td>Undisclosed</td><td>1301179</td></tr>\n",
       "<tr><td>Julie House</td><td>99587 Alyssa Springs</td><td>VIC</td><td>8111</td><td>Female</td><td>40044</td></tr>\n",
       "<tr><td>Janet Dixon</td><td>700 Sarah Stravenue</td><td>QLD</td><td>9001</td><td>Undisclosed</td><td>1109674</td></tr>\n",
       "<tr><td>Gerald Floyd</td><td>032 Jennifer Ligh...</td><td>VIC</td><td>8120</td><td>Male</td><td>422404</td></tr>\n",
       "<tr><td>Laura Reed</td><td>837 Thomas Hill S...</td><td>QLD</td><td>9002</td><td>Female</td><td>263478</td></tr>\n",
       "<tr><td>Kathleen Lane</td><td>67529 Rebecca Curve</td><td>VIC</td><td>8111</td><td>Female</td><td>1305561</td></tr>\n",
       "<tr><td>Brian Potter</td><td>573 Woods Stravenue</td><td>QLD</td><td>9010</td><td>Male</td><td>1229991</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+-------------------+--------------------+-----+--------+-----------+-----------+\n",
       "|               name|             address|state|postcode|     gender|consumer_id|\n",
       "+-------------------+--------------------+-----+--------+-----------+-----------+\n",
       "|  Mrs. Cynthia Cook|  483 Caitlyn Valley|  VIC|    8070|     Female|     216120|\n",
       "|      Jennifer Wood|166 Miller Pass S...|  VIC|    8070|     Female|    1421589|\n",
       "|Christopher Johnson|   586 Kimberly Pine|  QLD|    9005|Undisclosed|     747767|\n",
       "|    Natalie Stewart|06565 Bullock For...|  VIC|    8009|     Female|    1019378|\n",
       "|     Heather Walker|   57761 Erin Square|  VIC|    8011|     Female|     175536|\n",
       "|     Nicole Aguirre|25436 Shepherd St...|  VIC|    8001|     Female|     506458|\n",
       "|    Kathleen Garcia| 369 Cannon Parkways|  VIC|    8120|     Female|     805144|\n",
       "|      Wendy Shepard|4120 Christopher ...|  VIC|    8111|     Female|    1242001|\n",
       "|   Joyce Wilson DDS|   10840 David Trail|  VIC|    8002|     Female|     940835|\n",
       "|      Alyssa Harris|    617 Carrie Track|  VIC|    8010|Undisclosed|      89478|\n",
       "|     Curtis Jimenez|563 Brown Creek S...|  VIC|    8070|       Male|     807165|\n",
       "|       Aaron Tanner|9235 Mcneil Overp...|  VIC|    8008|Undisclosed|     556898|\n",
       "|    Arthur Williams|99382 Carlos Squares|  QLD|    9013|       Male|     468665|\n",
       "|      Robert Miller|   66326 Tina Tunnel|  VIC|    8120|Undisclosed|    1301179|\n",
       "|        Julie House|99587 Alyssa Springs|  VIC|    8111|     Female|      40044|\n",
       "|        Janet Dixon| 700 Sarah Stravenue|  QLD|    9001|Undisclosed|    1109674|\n",
       "|       Gerald Floyd|032 Jennifer Ligh...|  VIC|    8120|       Male|     422404|\n",
       "|         Laura Reed|837 Thomas Hill S...|  QLD|    9002|     Female|     263478|\n",
       "|      Kathleen Lane| 67529 Rebecca Curve|  VIC|    8111|     Female|    1305561|\n",
       "|       Brian Potter| 573 Woods Stravenue|  QLD|    9010|       Male|    1229991|\n",
       "+-------------------+--------------------+-----+--------+-----------+-----------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer.where((col('postcode') < 800) | (col('postcode') > 8000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6863fddb",
   "metadata": {},
   "source": [
    "### User detail dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f48788",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_detail = spark.read.parquet(\"consumer_user_details.parquet\")\n",
    "user_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db06db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(consumer_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a52466",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_id = user_detail.toPandas()['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc5087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset details: \\n\\tNumber of rows: {user_detail.count()}\", \\\n",
    "      f\"\\n\\tNumber of distinct User ID: {user_detail.select('user_id').distinct().count()}\", \\\n",
    "      f\"\\n\\tNumber of distinct Consumer ID: {user_detail.select('consumer_id').distinct().count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d6495b",
   "metadata": {},
   "source": [
    "### Checking for missing values in user detail dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a457919",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_check(user_detail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c214cea",
   "metadata": {},
   "source": [
    "Note:\n",
    "- Due to a difference between the internal system and a poor design choice (for some reason), the transaction tables use a **surrogate key** for each new user_id. <font color='red'>**Transaction dataset uses `user_id` to map customer but customer data are mapped to their own unique `customer_id` so the user detail data serves to map those two together</font> \n",
    "- However, the Consumer table has a **unique ID (some are missing on purpose)** field which will require some form of mapping between consumer_id to user_id. <font color='red'>**Might require further investigation and decide on whether it is appropriate to remove</font> \n",
    "- An additional mapping table has been provided to join the two datasets together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48daeb03",
   "metadata": {},
   "source": [
    "# Transaction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22372cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction = spark.read.parquet(\"transactions_20210828_20220227_snapshot/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cf258a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Use the following code to load the transactions files if you have problems running the code above.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d6141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"transactions_20210228_20210827_snapshot/\"\n",
    "list_files = os.listdir(path)\n",
    "list_files = list_files[1:(len(list_files)-1)]\n",
    "list_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfba2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "from pyspark.sql import SparkSession\n",
    "import functools\n",
    " \n",
    "# explicit function\n",
    "def unionAll(dfs):\n",
    "    return functools.reduce(lambda df1, df2: df1.union(df2.select(df1.columns)), dfs)\n",
    "\n",
    "# insert datetime\n",
    "file_name = os.listdir(path+ list_files[0])[1]\n",
    "transaction = spark.read.parquet(path+ list_files[0] +\"/\" + file_name)\n",
    "for i in list_files[1:]:\n",
    "    file_name = os.listdir(path + i)[1]\n",
    "    tmp = spark.read.parquet(path+ i +\"/\" + file_name)\n",
    "    transaction = unionAll([transaction, tmp] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a8f867",
   "metadata": {},
   "source": [
    "### Inspecting transaction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5790fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eb3520",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.write.parquet(\"/Users/oliver/Downloads/sales_by_region.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e64ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date, max_date = transaction.select(min(\"order_datetime\"), max(\"order_datetime\")).first()\n",
    "\n",
    "print(f\"Dataset details: \\n\\tNumber of rows: {transaction.count()}\", \\\n",
    "      f\"\\n\\tNumber of distinct order: {transaction.select('order_id').distinct().count()}\", \\\n",
    "      f\"\\n\\tPeriod: {min_date} - {max_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169e0ae7",
   "metadata": {},
   "source": [
    "### Checking for missing values in transaction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21080cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_check(transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab859e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_cust_id = transaction.select('user_id').toPandas()['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79331ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_id = set(consumer_id)\n",
    "transaction_cust_id = set(transaction_cust_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81205c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transaction_cust_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57281449",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(transaction_cust_id.intersection(consumer_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d438def5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7ae258",
   "metadata": {},
   "source": [
    "# Merchant dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddc32c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant = spark.read.parquet(\"tbl_merchants.parquet\")\n",
    "merchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0eab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742580a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset details: \\n\\tNumber of rows: {merchant.count()}\", \\\n",
    "      f\"\\n\\tNumber of distinct Merchant ABN: {merchant.select('merchant_abn').distinct().count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3999afc",
   "metadata": {},
   "source": [
    "### Checking for missing values in merchant dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3ae0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_check(merchant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edad95ea",
   "metadata": {},
   "source": [
    "### The tags column consists of tags, revenue levels and take rate of a merchant\n",
    "- **Revenue Levels**: (a, b, c, d, e) represents the **level of revenue bands** (unknown to groups). a denotes the smallest band whilst e denotes the highest revenue band. <font color='red'>**Highly relevant in ranking merchant</font> \n",
    "- **Take Rate**: the **fee charged by the BNPL firm** to a merchant on a transaction. That is, for each transaction made, a certain percentage is taken by the BNPL firm.<font color='red'>**Highly relevant in ranking merchant</font> \n",
    "- The dataset has been created to mimic a Salesforce data extract (i.e salespeople will type in tags and segments within a **free-text** field). <font color='red'>This suggests use of lemmatizating/stemming/fuzzy methods to group similar texts?</font> \n",
    "- As such, please be aware of small **human errors** when parsing the dataset.\n",
    "- For Example, the tag field may have errors as they were manually input by employees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864bcbb6",
   "metadata": {},
   "source": [
    "Since the data is small, we will be using Pandas to deal with Merchant data for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd295f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant = merchant.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42711880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first 5 rows for \"tags\"\n",
    "for idx, row in merchant.head(5).iterrows():\n",
    "    print(row['tags'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba957ed",
   "metadata": {},
   "source": [
    "### Extract Revenue Levels and Take Rate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_tags(merchant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16619ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract tags, revenue level and take rate from tags column\n",
    "def extract_tags(arr, category='tags'):\n",
    "    \n",
    "    # Split tags into the three components\n",
    "    arr = arr[1:-1]\n",
    "    split_arr = re.split('\\), \\(|\\], \\[', arr.strip('[()]'))\n",
    "    \n",
    "    if category == 'take_rate':\n",
    "        return re.findall('[\\d\\.\\d]+', split_arr[2])[0]\n",
    "    \n",
    "    elif category == 'revenue_level':\n",
    "        return split_arr[1].lower()\n",
    "    \n",
    "    # by default return tags\n",
    "    return split_arr[0].lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf8d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all three components in tags as standalone columns\n",
    "merchant['take_rate'] = merchant['tags'].apply(lambda x : extract_tags(x, 'take_rate'))\n",
    "merchant['revenue_level'] = merchant['tags'].apply(lambda x : extract_tags(x, 'revenue_level'))\n",
    "merchant['tags'] = merchant['tags'].apply(lambda x : extract_tags(x, 'tags'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ce5f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we extracted the take_rate and rev_level values correctly\n",
    "print(f\"Unique value in Revenue Level: {merchant['revenue_level'].unique()}\")\n",
    "print(f\"Range of Take Rate: {merchant['take_rate'].min()} - {merchant['take_rate'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f51e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data type for columns\n",
    "merchant.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a36470",
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant['take_rate'] = pd.to_numeric(merchant['take_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f7e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data type for columns\n",
    "merchant.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d860f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant.to_csv('../curated/clean_merchant.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5ce1fd",
   "metadata": {},
   "source": [
    "# Aggregation\n",
    "\n",
    "Here we generate various aggregate data to supplement our analyses and modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f6168",
   "metadata": {},
   "source": [
    "### Merchant Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054be57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data which summarizes merchants' sales\n",
    "merchant_sales = (transaction.groupby('merchant_abn', 'order_datetime')\n",
    "                             .agg({'dollar_value':'sum',\n",
    "                                   'order_id':'count'})\n",
    "                             .withColumnRenamed('sum(dollar_value)', 'sales_revenue')\n",
    "                             .withColumnRenamed('count(order_id)', 'no_orders'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d356826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88dd739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "merchant_sales.write.parquet(\"../curated/merchant_sales.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b6df5b",
   "metadata": {},
   "source": [
    "### Customers Purchase Behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2ede29",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc76430",
   "metadata": {},
   "outputs": [],
   "source": [
    "half_transaction = transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a249d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "half_transaction.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e1b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data which summarizes customers spendings\n",
    "customer_purchases = (transaction.groupby('user_id', 'order_datetime')\n",
    "                                 .agg({'dollar_value':'sum',\n",
    "                                       'order_id':'count'})\n",
    "                                 .withColumnRenamed('sum(dollar_value)', 'dollar_spent')\n",
    "                                 .withColumnRenamed('count(order_id)', 'no_orders'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3085f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cc4b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546f16ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "customer_purchases.write.parquet(\"../curated/customer_purchase_behaviour.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba877e0a",
   "metadata": {},
   "source": [
    "### Sales by Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b4364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join transaction data with customer data\n",
    "customer_transaction = (half_transaction.join(\n",
    "                            user_detail, \n",
    "                            half_transaction.user_id == user_detail.user_id,\n",
    "                            how = 'left_outer'\n",
    "                        ).drop(\n",
    "                            user_detail.user_id\n",
    "                        ))\n",
    "\n",
    "# customer_transaction = (customer_transaction.join(consumer, customer_transaction.consumer_id == consumer.consumer_id)\n",
    "#                                             .drop(consumer.consumer_id)\n",
    "#                                             .select(transaction['*'], consumer.postcode, consumer.state, consumer.gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af4bab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_check(customer_transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8194ecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_transaction.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba55624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "customer_transaction.write.parquet(\"../curated/customer_join_transaction.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4b4cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate by state -> postcode -> date\n",
    "sales_by_region = (customer_transaction.groupby('state', 'postcode', 'order_datetime')\n",
    "                                       .agg({'dollar_value':'sum',\n",
    "                                             'order_id':'count'})\n",
    "                                       .withColumnRenamed('sum(dollar_value)', 'dollar_spent')\n",
    "                                       .withColumnRenamed('count(order_id)', 'no_orders'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379cb869",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_by_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d53f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "sales_by_region.write.parquet(\"../curated/sales_by_region.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
