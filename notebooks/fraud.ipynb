{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# # Set working directory\n",
    "# if not \"/data/tables\" in os.getcwd():\n",
    "#     os.chdir(\"../data/tables\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.shell import spark\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"MAST30034 Project 2\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Fraud data from the transaction set\n",
    "since fraud data is only a small subset of the data, consider remove all transaction entries with fraud probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert merchant fraud, consumer fraud to spark df\n",
    "merchant_fraud_df = pd.read_csv(\"../data/tables/merchant_fraud_probability.csv\")\n",
    "merchant_fraud_df.to_parquet(\"../data/temp/merchant_fraud\")\n",
    "merchant_fraud_sdf = spark.read.parquet(\"../data/temp/merchant_fraud\")\n",
    "\n",
    "consumer_fraud_df = pd.read_csv(\"../data/tables/consumer_fraud_probability.csv\")\n",
    "consumer_fraud_df.to_parquet(\"../data/temp/consumer_fraud\")\n",
    "consumer_fraud_sdf = spark.read.parquet(\"../data/temp/consumer_fraud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all transaction data to a spark dataframe: transaction\n",
    "transaction_sdf1 = spark.read.parquet(\"../data/tables/transactions_20210228_20210827_snapshot\")\n",
    "transaction_sdf2 = spark.read.parquet(\"../data/tables/transactions_20210828_20220227_snapshot\")\n",
    "transaction_sdf3 = spark.read.parquet(\"../data/tables/transactions_20220228_20220828_snapshot\")\n",
    "transaction = transaction_sdf1.union(transaction_sdf2).union(transaction_sdf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all transaction on merchant fraud day\n",
    "merchant_fraud_sdf = spark.read.parquet(\"../data/temp/merchant_fraud\")\n",
    "merchant_transaction_on_fraud_day = transaction.join(merchant_fraud_sdf.select([\"merchant_abn\",\"order_datetime\"]), on=[\"merchant_abn\",\"order_datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- merchant_abn: long (nullable = true)\n",
      " |-- dollar_value: double (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- order_datetime: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transaction.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- merchant_abn: long (nullable = true)\n",
      " |-- order_datetime: date (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- dollar_value: double (nullable = true)\n",
      " |-- order_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merchant_transaction_on_fraud_day.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all transaction on consumer fraud day\n",
    "consumer_fraud_sdf = spark.read.parquet(\"../data/temp/consumer_fraud\")\n",
    "consumer_transaction_on_fraud_day = transaction.join(consumer_fraud_sdf.select([\"user_id\",\"order_datetime\"]), on=[\"user_id\",\"order_datetime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter fraud transactions\n",
    "order = [\"user_id\",\"merchant_abn\",\"dollar_value\",\"order_id\",\"order_datetime\"]\n",
    "transaction_fraud_rm = transaction.subtract(merchant_transaction_on_fraud_day.select(order)).subtract(consumer_transaction_on_fraud_day.select(order))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transaction_fraud_rm can be used for further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive fraud rate and other features\n",
    "\n",
    "#### Definition:\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
