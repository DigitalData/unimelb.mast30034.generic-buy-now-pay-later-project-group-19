{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787f07e0",
   "metadata": {},
   "source": [
    "# Testing environment to transfer functions to scipt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d13065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "os.chdir(\"/Users/oliver/Documents/GitHub/generic-buy-now-pay-later-project-group-19/scripts\")\n",
    "import sys\n",
    "import argparse\n",
    "import re\n",
    "# ... TODO: Add to this as necessary\n",
    "\n",
    "# External Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "# ... TODO: Add to this as necessary\n",
    "\n",
    "# Our Modules\n",
    "from utilities.log_utilities import logger\n",
    "import utilities.print_utilities as PRINT\n",
    "import utilities.read_utilities as READ\n",
    "import utilities.clean_utilities as CLEAN\n",
    "import utilities.agg_utilities as AGG\n",
    "import utilities.write_utilities as WRITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d76e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "        SparkSession.builder.appName(\"MAST30034 Project 2\")\n",
    "        .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "        .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "        .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "        .config(\"spark.driver.memory\", \"4g\")\n",
    "        .getOrCreate()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f223f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe03fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = READ.read_data(spark, \"../data/tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6321f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN.clean_data(spark, data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7f9050",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce305e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_2 = data_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbab8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55079c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGG.compute_aggregates(spark, data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87780fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08456289",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def compute_merchant_metric(spark: SparkSession, merchant_sales: DataFrame,\n",
    "                           merchant: DataFrame) -> DataFrame:\n",
    "    \n",
    "    \n",
    "    # This part is taking a while \n",
    "    date_range = merchant_sales.select(F.min(F.col(\"order_datetime\")), \n",
    "                                       F.max(F.col(\"order_datetime\"))\n",
    "                                      ).first()\n",
    "    \n",
    "    min_date, max_date = (datetime.strptime(date_range[0], \"%Y-%m-%d\"), \n",
    "                          datetime.strptime(date_range[1], \"%Y-%m-%d\"))\n",
    "    \n",
    "    num_days = (max_date - min_date).days\n",
    "    \n",
    "    # Group first to reduce the table size before joining\n",
    "    merchant_daily_sales = merchant_sales.groupby('merchant_abn').agg(\n",
    "        (F.sum(F.col('sales_revenue')) / num_days).alias('avg_daily_rev'),\n",
    "        (F.sum(F.col('sales_revenue')) / F.sum(F.col('no_orders'))).alias('avg_value_per_order'),\n",
    "        (F.sum(F.col('no_orders')) / num_days).alias('avg_daily_order')\n",
    "    )\n",
    "    \n",
    "    merchant_daily_sales = merchant.join(\n",
    "        merchant_daily_sales, \n",
    "        on=[\"merchant_abn\"],\n",
    "        how='left'\n",
    "    ).toPandas()\n",
    "    \n",
    "    \n",
    "    merchant_daily_sales['avg_daily_commission'] = merchant_daily_sales['avg_daily_rev'] * (merchant_daily_sales['take_rate']/100)\n",
    "    merchant_daily_sales['avg_commission_per_order'] = merchant_daily_sales['avg_value_per_order'] * (merchant_daily_sales['take_rate']/100)\n",
    "    \n",
    "    return merchant_daily_sales\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4813f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['merchant_sales'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b31b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['merchant_summary'] = compute_merchant_metric(spark, data_dict['merchant_sales'], data_dict['merchants'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad18ad4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = data_dict['merchant_sales'].select(F.min(F.col(\"order_datetime\")), F.max(F.col(\"order_datetime\"))).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce5b1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
